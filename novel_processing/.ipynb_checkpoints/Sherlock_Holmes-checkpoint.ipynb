{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import csv\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the novel variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = #novel number\n",
    "t = #novel name\n",
    "s = #how many rows to skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the novels from Gutenberg.\n",
    "* Strip them of unwanted information.\n",
    "* Tokenize the text into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "novel = strip_headers(load_etext(n))\n",
    "novel = novel.replace('\\n', ' ')\n",
    "novel= TextBlob(novel)\n",
    "novel_sentences = novel.sentences\n",
    "novel_title = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the sentences to a csv file. \n",
    "-There is a bug I haven't figure out yet that requires me to write to csv twice to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in range(2):\n",
    "    novelWriter = csv.writer(open('data/novel_'+novel_title+'.csv', 'w'), delimiter=',')\n",
    "    for sentence in novel_sentences:\n",
    "        novelWriter.writerow([sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the csv file to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel = pd.read_csv('data/novel_'+novel_title+'.csv', skiprows = s, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the wrd_length and total_char columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrd_length = []\n",
    "total_char = []\n",
    "def wrd_char_counts(sentence):\n",
    "    total_chars = 0\n",
    "    wrd_counts = []\n",
    "    for word in sentence:\n",
    "        char_count = len(word)\n",
    "        wrd_counts.append(char_count)\n",
    "        total_chars += char_count\n",
    "    total_char.append(total_chars)\n",
    "    wrd_length.append(wrd_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in df_novel[0]:\n",
    "    sent = TextBlob(l)\n",
    "    wrd_char_counts(sent.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel['wrd_length'] = wrd_length\n",
    "df_novel['total_char'] = total_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create syllable count column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CountSyllables(word, isName=True):\n",
    "    vowels = \"aeiouy\"\n",
    "    #single syllables in words like bread and lead, but split in names like Breanne and Adreann\n",
    "    specials = [\"ia\",\"ea\"] if isName else [\"ia\"]\n",
    "    specials_except_end = [\"ie\",\"ya\",\"es\",\"ed\"]  #seperate syllables unless ending the word\n",
    "    currentWord = word.lower()\n",
    "    numVowels = 0\n",
    "    lastWasVowel = False\n",
    "    last_letter = \"\"\n",
    "\n",
    "    for letter in currentWord:\n",
    "        if letter in vowels:\n",
    "            #don't count diphthongs unless special cases\n",
    "            combo = last_letter+letter\n",
    "            if lastWasVowel and combo not in specials and combo not in specials_except_end:\n",
    "                lastWasVowel = True\n",
    "            else:\n",
    "                numVowels += 1\n",
    "                lastWasVowel = True\n",
    "        else:\n",
    "            lastWasVowel = False\n",
    "\n",
    "        last_letter = letter\n",
    "\n",
    "    #remove es & ed which are usually silent\n",
    "    if len(currentWord) > 2 and currentWord[-2:] in specials_except_end:\n",
    "        numVowels -= 1\n",
    "\n",
    "    #remove silent single e, but not ee since it counted it before and we should be correct\n",
    "    elif len(currentWord) > 2 and currentWord[-1:] == \"e\" and currentWord[-2:] != \"ee\" and currentWord != 'the':\n",
    "        numVowels -= 1\n",
    "\n",
    "    return numVowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syl = []\n",
    "for l in df_novel[0]:\n",
    "    sent = TextBlob(l)\n",
    "    syl_single = []\n",
    "    for x in sent.words:\n",
    "        m = CountSyllables(x)\n",
    "        syl_single.append(m)\n",
    "    syl.append(syl_single)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syl_count_arr = []\n",
    "for n in syl:\n",
    "    n = np.array(n)\n",
    "    syl_count_arr.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel['syl_count'] = syl_count_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If novel has a lot of numbers for chapter headings.\n",
    "#d = df_novel[df_novel['total_char']<=2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create syllable sum column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syl_sum = []\n",
    "for l in range(0,len(df_novel)):\n",
    "    syl_sum.append(df_novel['syl_count'][l].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel['syl_sum'] = syl_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_sentiment(text):\n",
    "    return TextBlob(text.decode('utf-8')).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel['sentiment'] = df_novel[0].apply(detect_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write all columns to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel.to_csv('data/novel_'+novel_title+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "df_test = pd.read_csv('data/novel_'+novel_title+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cluster dataframe - remove columns that can't be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster = df_novel.drop('wrd_length', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster = df_cluster.drop('syl_count', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 20 clusters on scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_cluster.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=20, random_state=1)\n",
    "km.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers = df_cluster.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Scatter plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = np.array(['#0000ff', '#ff00ff', '#39b54a', '#ff0000', '#ffff00', '#000080', '#ff99ff', '#88d392', '#bf0000', '#b4ff33', '#0000bf', '#800080','#1d5b25', '#4d226d', '#2b6855', '#128ab2', '#6666ff', '#a381bd', '#333333','#a0d0e0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scatter plot of calories versus alcohol, colored by cluster (0=red, 1=green, 2=blue)\n",
    "plt.scatter(df_cluster.syl_sum, df_cluster.sentiment, c=colors[df_cluster.cluster], s=50)\n",
    "\n",
    "# cluster centers, marked by \"+\"\n",
    "plt.scatter(centers.syl_sum, centers.sentiment, linewidths=3, marker='+', s=300, c='black')\n",
    "\n",
    "# add labels\n",
    "plt.xlabel('syl_sum')\n",
    "plt.ylabel('sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_3 = df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_cluster_3.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3, random_state=1)\n",
    "km.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_3['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_3.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 Clusters with no syl_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_no_syl = df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_no_syl = df_cluster.drop('syl_sum', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_cluster_no_syl.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3, random_state=1)\n",
    "km.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_no_syl['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_no_syl.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 5 Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_5 = df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_cluster_5.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5, random_state=1)\n",
    "km.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_5['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_5.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find ideal amount of clusters for novel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import metrics\n",
    "metrics.silhouette_score(X_scaled, km.labels_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k_range = range(2,150)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=1)\n",
    "    km.fit(X_scaled)\n",
    "    scores.append(metrics.silhouette_score(X_scaled, km.labels_))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silihouette Coefficient')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Sentiment Pattern "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel['total_char'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = (df_novel['total_char'].sum()/20) - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "x = 0\n",
    "ratio = (df_novel['total_char'].sum()/20) - 100\n",
    "def find_this(t, x):\n",
    "    w = 0    \n",
    "    sent_stop = []\n",
    "    while w <= ratio:\n",
    "        w = df_novel['total_char'][t:x].sum()\n",
    "        sent_stop.append(x)\n",
    "        x += 1\n",
    "    return max(sent_stop)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "x = 0\n",
    "start_point = []\n",
    "stop_point = []\n",
    "for n in range(1, 21):\n",
    "    s = find_this(t, x)\n",
    "    print \"df_novel['total_char'][%s:%s]\" %(t, s)\n",
    "    start_point.append(t)\n",
    "    stop_point.append(s)\n",
    "    t = s\n",
    "    x = s + 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twenty_piece_char = []\n",
    "st = 0\n",
    "for l in start_point: \n",
    "    strt = start_point[st]\n",
    "    stp = stop_point[st]\n",
    "    print strt\n",
    "    print stp\n",
    "    mn = df_novel['sentiment'][strt:stp].mean()\n",
    "    twenty_piece_char.append(mn)\n",
    "    print mn\n",
    "    st +=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = np.array(n)\n",
    "twenty_piece_char = np.array(twenty_piece_char)\n",
    "print twenty_piece_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(20), twenty_piece_char)\n",
    "plt.ylabel('sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 piece sentiment pattern - need to fix this code for the three piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_novel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "x = 0\n",
    "ratio = (df_novel['total_char'].sum()/3) -100\n",
    "def find_this(t, x):\n",
    "    w = 0    \n",
    "    sent_stop = []\n",
    "    while w < ratio:\n",
    "        w = df_novel['total_char'][t:x].sum()\n",
    "        sent_stop.append(x)\n",
    "        x += 1\n",
    "    return max(sent_stop)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "x = 0\n",
    "start_point = []\n",
    "stop_point = []\n",
    "for n in range(1, 21):\n",
    "    s = find_this(t, x)\n",
    "    print \"df_novel['total_char'][%s:%s]\" %(t, s)\n",
    "    start_point.append(t)\n",
    "    stop_point.append(s)\n",
    "    t = s\n",
    "    x = s + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "three_piece_char = []\n",
    "st = 0\n",
    "for l in start_point: \n",
    "    strt = start_point[st]\n",
    "    stp = stop_point[st]\n",
    "    print strt\n",
    "    print stp\n",
    "    mn = df_novel['sentiment'][strt:stp].mean()\n",
    "    three_piece_char.append(mn)\n",
    "    print mn\n",
    "    st +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = np.array(n)\n",
    "three_piece_char = np.array(three_piece_char)\n",
    "print three_piece_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(3), three_piece_char)\n",
    "plt.ylabel('sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sentiment pattern based on ideal cluster numbers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
